\section{Discussion}
\subsection{Host Performance}
After testing the FFmpegOut plugin for Unity, we noticed that it had a peculiarity that negatively impacted performance. The plugin was actually recording every frame and used vertical synchronization to force the game to run at the same framerate as the one specified for recording. This was problematic as recorded videos are primarily handled in 30 and 60 frames per second while a game running in a VR environment targets 90 frames, as industry standard head-mounted displays like the HTC Vive have a refresh rate of 90Hz\cite{vive_specs}. We optimized this peculiarity away by introducing the concept of time into the logic of the plugin. This optimization consists of several changes. To start off, we removed vertical synchronization as it allows the game or application to render at an unlocked framerate. Instead of capturing images every frame we also now sample the camera at a rate of $1/recordingFramerate$ times per second to separate the recording from the game or application rendering. In general, this optimization provided double the framerate on our development machines compared to the original plugin. 

\subsubsection{Image Capture Offloading}
An alternative solution that has been discussed for reducing the streaming overhead of the host could be to have a dedicated spectator computer. Here the computer would join in the VR collaboration environment as a camera that the host could move around. With this solution, our current image capture implementation would be sufficiently efficient, as that computer would only need to process the image capture and streaming of the video, and no more than 30 frames per second would be required, which is a framerate we hit with our current solution.
    
\subsection{Strengths and Weaknesses of the Streaming Platforms}
While developing the prototype, we gained some experience with streaming to Twitch.tv and YouTube and learned several strengths and weaknesses for both platforms.

\subsubsection{Twitch.tv}
One of the benefits to Twitch.tv is that the stream data requirements, in general, are a lot more relaxed than YouTube. This means that the platform handles sudden connection spikes relatively well and requires fewer optimizations to the encoder for the service to accept the video stream. This is also coupled with a powerful analytics service which allows the streamer to check the data that is received. This was very useful during our development as we could use the analytics service to debug our data and find errors.

The primary weakness of using Twitch.tv was the latency to the client. In general, the latency from host to client ended up at around seven seconds, which is rather suboptimal for real-time interaction. 

\subsubsection{YouTube}
YouTube, in general, has proved to contrast Twitch.tv in several aspects. Stream data requirements are far stricter and require more consistency in data delivery. Furthermore, all streams are required to have an audio source, even if the source is completely silent or empty. There are also limited tools available for stream data analytics which makes it hard to understand the impact of various encoder settings when testing the platform. Finally, YouTube requires that the end user is a YouTube partner in order to embed the livestream player, which can result in additional time waiting for the partnership application to be approved. 

While YouTube generally is more difficult to work with there is also one aspect that the platform excels at: latency. In contrast to the seven second delay of Twitch.tv, we were able to achieve latencies of two to three seconds on YouTube which is quite a bit better for real-time usage and interaction. We would like to think that this latency could be further reduced with enough optimization of encoder settings and optimal networking conditions.

\subsection{Did the Final Prototype Satisfy the Requirements?}
Looking at the end result we can say that we have satisfied most of the functional requirements of the application. All the requirements have been implemented with the exception of chat, which was dropped due to the time and scope of the project. 

Requirement \ref{req:no_client_software}, relating to not requiring installation of software for the client should be functionally satisfied on desktop and laptop computers, however, we did not get to test the application on mobiles or tablets, so it is uncertain if the requirement is satisfied there. 

We would argue that we failed in satisfying Requirement~\ref{req:minimal_processing_client} as using a game engine like Unity is too much processing for such a simple application. Using a Javascript solution would be better, however, due to our inexperience with the alternative solutions, it is unsure if we would have been able to get a functional prototype based on the time and scope of the project.

Due to its nature, Requirement \ref{req:minimal_processing_host} is hard to evaluate, as it is never really finished. While we managed to improve the performance of the existing solutions we found, we believe the camera capture could still be improved by a large factor, and given more time we would have investigated this further.

As with the other operational requirements, Requirement~\ref{req:minimal_latency} is difficult to evaluate, as we are uncertain as to what is possible realistic latencies. During testing we achieved a minimum of two-three seconds delay on a WiFi connection, which we deem satisfactory for this project, however, we believe there might be room for more optimization on the FFmpeg side, which could further reduce the latency towards the one second mark.
